# üöÄ Projet 5: Pipeline ETL pour Donn√©es M√©dicales vers MongoDB

Ce projet met en place un pipeline ETL (Extract, Transform, Load) complet pour migrer un jeu de donn√©es de patients depuis un fichier CSV vers une base de donn√©es NoSQL MongoDB. La solution est enti√®rement conteneuris√©e avec Docker et Docker Compose pour garantir une portabilit√© et une reproductibilit√© parfaites.

## üéØ Contexte de la Mission

La mission, confi√©e par l'entreprise DataSoluTech, vise √† fournir √† un client une solution de stockage de donn√©es moderne, performante et scalable pour g√©rer l'historique m√©dical de ses patients. Le pipeline d√©velopp√© nettoie, structure et charge les donn√©es, tout en mettant en place un syst√®me d'authentification s√©curis√©.

---

## üèóÔ∏è Architecture de la Solution

La solution est orchestr√©e par Docker Compose et se compose de trois services principaux :

- **`etl-app`**: Un conteneur Python qui ex√©cute notre script ETL. Il lit le CSV, le transforme, et charge les donn√©es dans MongoDB.
- **`mongo`**: Le service de base de donn√©es MongoDB, configur√© avec un utilisateur administrateur et un utilisateur "analyste" en lecture seule.
- **`mongo-express`**: Une interface web d'administration pour visualiser et interroger facilement la base de donn√©es.

Les services communiquent entre eux sur un r√©seau Docker priv√© pour plus de s√©curit√©.

---

## üíæ Mod√©lisation des Donn√©es

Suite √† une analyse approfondie du jeu de donn√©es, nous avons d√©couvert que chaque ligne du CSV repr√©sentait une **hospitalisation** et non un patient unique. Le pipeline a donc √©t√© con√ßu pour supporter deux strat√©gies de mod√©lisation NoSQL, configurables via la variable `DATA_MODELLING_MODE` dans le fichier `.env`.

### 1. Mod√®le `embedding` (par d√©faut)
Ce mod√®le est optimis√© pour les lectures. Chaque document repr√©sente un patient unique et contient un tableau imbriqu√© de toutes ses hospitalisations.

**Exemple de document `patients`:**
```json
{
  "_id": "hash_du_patient",
  "name": {
    "full": "Mr. Brandon Johnson Jr.",
    "title": "Mr.", 
    "first": "Brandon",
    "last": "Johnson",
    "suffix": "Jr.", 
    // Note: Les champs 'title' et 'suffix' sont optionnels.
  },
  "gender": "Male",
  "blood_type": "B+",
  "hospitalizations": [
    {
      "test_results": "Normal",
      "hospital": "Sons and Miller",
      "admission_type": "Urgent",
      "date_of_admission": "2023-11-12T00:00:00Z",
      "discharge_date": "2023-11-13T00:00:00Z",
      "insurance_provider": "Blue Cross",
      "admission_age": 79,
      "medication": "Paracetamol",
      "billing_amount": 6612.15,      
      "medical_condition": "Cancer",
      "doctor": "Amber Payne",
      "room_number": 328
    },
    {
      "admission_age": 83,
      "date_of_admission": "2023-11-12T00:00:00Z",
      "doctor": "Amber Payne",
      // ... autres champs du s√©jour (chambre, m√©dication, etc.)
    }
  ]
}
```

### 2. Mod√®le `reference`
Ce mod√®le normalise les donn√©es dans deux collections distinctes, ce qui est id√©al pour les environnements avec de nombreuses mises √† jour.
- **`patients`**: Contient les informations uniques de chaque patient.
- **`hospitalizations`**: Contient les d√©tails de chaque s√©jour, avec un champ `patient_id` faisant r√©f√©rence √† la collection `patients`.

---

## üöÄ Installation et Lancement

Suivez ces √©tapes pour lancer le projet complet.

### 1. Pr√©requis
- [Docker](https://www.docker.com/products/docker-desktop/) et Docker Compose install√©s.
- Git install√©.

### 2. Cloner le D√©p√¥t
```bash
git clone https://github.com/abguven/P5-medical-data-etl-pipeline.git
cd P5-medical-data-etl-pipeline
```

### 3. Configurer les Variables d'Environnement
Le projet utilise des variables d'environnement pour g√©rer les secrets et la configuration.

Copiez le fichier d'exemple et personnalisez-le si n√©cessaire (notamment les mots de passe).
```bash
cp .env.example .env
```
Ouvrez le fichier `.env` et modifiez les valeurs `MONGO_PASSWORD` et `WEB_PASSWORD`. Vous pouvez aussi changer le `DATA_MODELLING_MODE` pour tester les deux strat√©gies.

### 4. Lancer le Pipeline Complet
Cette commande va construire l'image Python, d√©marrer la base de donn√©es, ex√©cuter le script ETL, puis lancer l'interface web.

```bash
# Lancer tous les services en arri√®re-plan
docker-compose up -d --build
```
Le pipeline s'ex√©cute automatiquement au d√©marrage. La premi√®re ex√©cution peut prendre un peu de temps pour t√©l√©charger les images et installer les d√©pendances.

---

## üõ†Ô∏è Utilisation et Monitoring

### Acc√©der aux Donn√©es
- **Mongo Express (Interface Web)**: Ouvrez votre navigateur et allez sur [http://localhost:8081](http://localhost:8081).
  - Utilisez les identifiants `WEB_USERNAME` et `WEB_PASSWORD` d√©finis dans votre fichier `.env` pour vous connecter.

### Monitoring et Debug
```bash
# Voir les logs en temps r√©el de tous les services
docker-compose logs -f

# Voir les logs sp√©cifiques du script ETL
docker-compose logs etl-app

# Entrer dans le conteneur ETL pour un debug avanc√©
docker-compose exec etl-app bash
```

### Arr√™ter les Services
Pour arr√™ter tous les conteneurs :
```bash
docker-compose down
```
Pour un nettoyage complet (incluant la suppression du volume de donn√©es MongoDB) :
```bash
docker-compose down -v
```

---

## üß™ Scripts d'Exploration

Le dossier `notebooks_and_tests/` contient des scripts utilis√©s durant la phase de d√©veloppement pour valider certains points de la mission.
- **`crud_examples.py`**: D√©montre les op√©rations CRUD de base sur une instance MongoDB locale.